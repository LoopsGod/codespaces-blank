working_on_qlina_advanced_3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sCJ_888xQh82-lTPyNSioH6NnwxCU_E0

Current flow:

1.   Download pptx templates Canva
2.   Convert each slide to a json format understandable for LLM
3.   Given text/topic and number of slides build an order list of which template building blocks will be used
4.   Create a json format for the new structure including placeholders needed to be changed
5.   Send the format to LLM who gives content back
6.   Use other library for duplicating buildingblocks to new powerpoint
7.   Insert information

TO-DO:
- Add title + status+ pdf + pptx 
- input pdf, docx and string (not base64)
- OpenAI response refusal error logic
- Switch to mini (latest mini where possible)
- General error handling
- Add more templates
- Languages (yes you have to make it in different languages the prompt)
- Make sure that placeholder ID is also part of pydantic in prompt 2
- Only works with 1 image per slide
- Image retrieval : upgrade to google search? with filter (5$ per 1k searches)
- PDF/DOCX Safety api call 
- Clean-up Lambda or at least files in the tmp directory
- Generate_presentation_plan() change to gpt-4o-mini? Or back to 4o
- Download actual template based on choice
- In documents spaces are also tokens - reduce for cost

DONE:
- When inserting the image do a check if the image is actually there and not hallucination ✅
- Replacement content must be same amount of characters ✅
- Allow images from original text file to be inserted? ✅
- Implement image retrieval ✅
